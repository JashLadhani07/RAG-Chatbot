{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8465c22-c9e9-4207-b862-f24d6b0ff45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q --upgrade langchain\n",
    "pip install -q --upgrade langchain-google-genai \n",
    "pip install -q --upgrade google-generativeai  \n",
    "pip install -q --upgrade langchain-core \n",
    "pip install -q --upgrade langchain_community \n",
    "pip install -q --upgrade docx2txt \n",
    "pip install -q --upgrade pypdf \n",
    "pip install -q --upgrade langchain_chroma\n",
    "pip install -q --upgrade chromadb\n",
    "pip install -q --upgrade sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469a5c08-d0d1-44b6-9a71-2a1b3ce70598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\ladha\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c086eb6c-d5cf-42ff-b524-88fc10086304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip uninstall -y google-generativeai google-ai-generativelanguage langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a9c0c5a-d1c4-45a3-a4b9-000608bff68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q --upgrade langchain langchain-core langchain-community\n",
    "#!pip install -q --upgrade langchain-google-genai google-generativeai==0.8.5 google-ai-generativelanguage==0.6.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a102dd0-d59d-4ca5-8a58-16ac89b172dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import langchain\n",
    "from dotenv import load_dotenv\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9a70b24-4bb5-4193-be17-57fa832535c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling LLM inside the langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdb0025c-a1c4-4c7e-bf8e-1a4361a8b9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import google.generativeai as genai\n",
    "#genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "#llm = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "#llm_response = llm.generate_content(\"Hello\")\n",
    "#print(llm_response.text)\n",
    "\n",
    "#We dont use this as it is raw Gemini SDK but we need Langchain wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6795d4e-27ab-48d3-aded-8ac80a2fd409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG (Retrieval Augmented Generation) retrieves external information to augment a Large Language Model's (LLM) generation, providing more accurate and relevant answers.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file from the current directory\n",
    "load_dotenv()\n",
    "\n",
    "# Fetch keys\n",
    "gemini_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "langchain_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Check if keys were loaded correctly\n",
    "if not gemini_key:\n",
    "    raise ValueError(\"GOOGLE_API_KEY not found in .env file\")\n",
    "if not langchain_key:\n",
    "    raise ValueError(\"LANGCHAIN_API_KEY not found in .env file\")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_key\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = langchain_key\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain_course\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# Initialize Gemini LLM\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "\n",
    "# Test call\n",
    "llm_response = llm.invoke(\"Hello, what is RAG? Explain in 1 line\")\n",
    "print(llm_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "801fc752-5ee4-4026-ba36-dd463e5f7a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY: None\n",
      "LANGCHAIN_API_KEY: None\n"
     ]
    }
   ],
   "source": [
    "#Model works \n",
    "#This also creates LangSmith Tracing course which we need. This couldn't be created using raw Gemini SDK, Therefore we need Langchain Wrappers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0830f6b-4597-408c-bf25-c67919c4f3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RAG retrieves relevant external information to ground and improve an LLM's answer, making it more accurate and less prone to hallucination.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parsing Output #AI Message in openai is different, and from that we need only plain text, so we have to parse\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parsers = StrOutputParser()\n",
    "output_parsers.invoke(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4119019c-63b0-46d8-835c-2176f1769ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple Chain\n",
    "chain = llm | output_parsers\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448575fd-3264-4a02-b817-cf7add312fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone_model='Galaxy S21' rating=4.0 pros=['Gorgeous screen', 'Amazing camera, especially at night', 'Solid battery life'] cons=['Pricey', 'No charger included', 'New button layout takes getting used to (Bixby button issues)'] summary='Great phone with a few annoying quirks, but definitely worth checking out for an upgrade.'\n"
     ]
    }
   ],
   "source": [
    "#To create a structured output from plain text\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "class MobileReview(BaseModel):\n",
    "    phone_model: str = Field(description=\"Name and model of phone\")\n",
    "    rating: float = Field(description=\"Overall rating of the phone\")\n",
    "    pros: List[str] = Field(description=\"List of positive aspects\")\n",
    "    cons: List[str] = Field(description=\"List of negative aspects\")\n",
    "    summary: str = Field(description=\"Brief summary of the reivew\")\n",
    "\n",
    "review_text = \"\"\"\n",
    "Just got my hands on the new Galaxy S21 and wow, this thing is slick! The screen is gorgeous,\n",
    "colors pop like crazy. Camera's insane too, especially at night - my Insta game's never been\n",
    "stronger. Battery life's solid, lasts me all day no problem.\n",
    "Not gonna lie though, it's pretty pricey. And what's with ditching the charger? C'mon Samsung.\n",
    "Also, still getting used to the new button layout, keep hitting Bixby by mistake.\n",
    "Overall, I'd say it's a solid 4 out of 5. Great phone, but a few annoying quirks keep it from\n",
    "being perfect. If you're due for an upgrade, definitely worth checking out!\n",
    "\"\"\"\n",
    "\n",
    "structured_llm = llm.with_structured_output(MobileReview)\n",
    "output = structured_llm.invoke(review_text)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "631292e2-60e4-42d3-a7de-d3e53234c310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one that's both historical and literal:\n",
      "\n",
      "You know the term \"bug\" in programming, right? It refers to an error or flaw in code. Well, the term comes from an **actual bug!**\n",
      "\n",
      "On **September 9, 1947**, computer pioneer Grace Hopper and her team at Harvard were working on the Mark II Aiken Relay Calculator. They couldn't figure out why the machine was malfunctioning. After much searching, they found a **moth** trapped in one of the relays, causing the error.\n",
      "\n",
      "They carefully removed the moth and taped it into their logbook, with the note: **\"First actual case of bug being found.\"**\n",
      "\n",
      "This literal event is the origin of the terms \"bug\" for a computer error and \"debugging\" for the process of finding and fixing those errors!\n"
     ]
    }
   ],
   "source": [
    "#We create prompt templates to make the model i/p dynamic\n",
    "#Till now we used static input, now using prompt template we will make it dynamic\n",
    "#Here we use LCEL\n",
    "#Instead of writing a plain string, you define a template with placeholders.\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Tell me an interesting fact about {topic}\") #This creates a reusable prompt template\n",
    "chain = prompt | llm | output_parsers #we create prompt first, which is sent to llm which is then parsed\n",
    "result = chain.invoke({\"topic\": \"programming\"})\n",
    "print(result)\n",
    "\n",
    "#chain = prompt → LLM → parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da89c91a-1246-44f4-91e3-9ace1dceea9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Programming is a fascinating field that underpins almost everything we do in the digital world! Here are some interesting facts about it:\\n\\n1.  **The World\\'s First Computer Programmer was a Woman:** Ada Lovelace, daughter of the poet Lord Byron, is often credited with writing the first algorithm intended to be carried out by Charles Babbage\\'s Analytical Engine in the mid-19th century.\\n2.  **The Original \"Computers\" Were Human:** Before electronic computers, \"computers\" were often women who performed complex mathematical calculations by hand, especially during wartime for ballistics trajectories. When the ENIAC (one of the first electronic computers) was built, these women were the ones who learned to program it by wiring switches and cables.\\n3.  **\"Bugs\" Come from a Real Moth:** The term \"bug\" for an error in code originated in 1947 when computer pioneer Grace Hopper found an actual moth trapped in the Harvard Mark II computer\\'s relay, causing a malfunction. She taped the moth into her logbook with the note: \"First actual case of bug being found.\"\\n4.  **Binary is the Computer\\'s True Language:** At its core, all programming boils down to binary code – sequences of 0s and 1s. This is the only language computers truly understand, representing electrical signals being on or off.\\n5.  **Thousands of Programming Languages Exist:** While popular ones like Python, Java, C++, and JavaScript get most of the attention, there are literally thousands of programming languages, each with its own syntax, purpose, and strengths.\\n6.  **Programming is More About Problem-Solving than Typing:** While writing code is part of it, the majority of a programmer\\'s time is spent understanding a problem, designing a solution, debugging errors, and refining their logic. It\\'s like solving a complex puzzle.\\n7.  **Algorithms Are Everywhere:** An algorithm is essentially a step-by-step recipe for solving a problem or performing a task. From the way Google ranks search results to how Netflix recommends movies, algorithms are the invisible engines driving our digital experiences.\\n8.  **Code is Ubiquitous:** You might not see it, but code runs almost everything around you – your smartphone, smart TV, car, microwave, traffic lights, medical devices, satellites, and even the washing machine.\\n9.  **Debugging is a Huge Part of the Job:** Programmers often spend more time debugging (finding and fixing errors in their code) than writing new code. It\\'s an essential skill that requires patience and detective work.\\n10. **Open Source Drives Much of the Internet:** Many of the tools and systems that power the internet and modern software are \"open source,\" meaning their code is freely available for anyone to view, modify, and distribute. Linux, WordPress, and Android are prime examples.\\n\\nProgramming is a dynamic and ever-evolving field that combines logic, creativity, and persistent problem-solving to build the digital world we live in!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--bb50deab-7384-4c78-a1d3-b1434c2cf403-0', usage_metadata={'input_tokens': 14, 'output_tokens': 625, 'total_tokens': 1969, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can use LLM Messages to pass a list of messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "system_messages = SystemMessage(content=\"You are a helpful assistant that provides interesting facts\")\n",
    "human_messages = HumanMessage(content = \"Tell me about programming\")\n",
    "llm.invoke([system_messages,human_messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80fc9471-6015-4d67-bc93-6aa92e33cfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='That\\'s a fantastic topic! Programming is truly the hidden language of our modern world. Here are a few interesting facts about it:\\n\\n1.  **It\\'s Like Writing a Recipe for a Computer:** At its core, programming is about writing a set of instructions, called \"code,\" that tells a computer exactly what to do. Think of it like a super detailed recipe: if you miss a step or get it wrong, the computer won\\'t know what to do, or it will produce something unexpected!\\n\\n2.  **The First Programmer Was a Woman:** The very first computer programmer is widely considered to be **Ada Lovelace**, the daughter of the poet Lord Byron. Back in the mid-1800s, she wrote what\\'s often recognized as the first algorithm intended to be carried out by a machine – Charles Babbage\\'s analytical engine. She saw the potential for computers to do far more than just calculations!\\n\\n3.  **There Are Hundreds of Programming Languages:** Just like humans speak different languages, computers understand different \"programming languages.\" Some popular ones include:\\n    *   **Python:** Great for beginners, data science, and web development.\\n    *   **JavaScript:** The language of the internet, making websites interactive.\\n    *   **C++:** Used for high-performance applications like games and operating systems.\\n    *   **Java:** Powers many enterprise systems and Android apps.\\n    Each language has its strengths and is suited for different kinds of tasks!\\n\\n4.  **It\\'s Everywhere You Look:** From the phone in your pocket to the traffic lights on the street, the apps you use, the movies you stream, the cars you drive, and even the rockets that go to space – almost everything digital around us is powered by programming. It\\'s the silent engine of our technological age.\\n\\n5.  **\"Debugging\" Comes from a Real Bug!** The term \"debugging\" (finding and fixing errors in code) became popular after computer pioneer Grace Hopper found an actual moth stuck in a relay of the Mark II computer in 1947, causing it to malfunction. She taped the moth into her logbook with the note: \"First actual case of bug being found.\"\\n\\nIt\\'s a field that combines logic, creativity, and problem-solving, and it\\'s constantly evolving!' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--b62d5c4d-ed54-442e-b03d-8aa04fe80a87-0' usage_metadata={'input_tokens': 15, 'output_tokens': 486, 'total_tokens': 972, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "#A different method for creating prompt template\n",
    "#Passing a list instead of string with \n",
    "#this method basically merges prompt templates and LLM messages in a single method\n",
    "template = ChatPromptTemplate([\n",
    "        (\"system\", \"You are a helpful assistant that tells interesting facts.\"),\n",
    "        (\"human\", \"Tell me about {topic}\")\n",
    "    ])\n",
    "chain = template | llm\n",
    "response = chain.invoke({\"topic\": \"programming\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e36d297-bd2e-40a3-b47d-a83ceffae494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 documents from the folder.\n",
      "Split the documents into 41 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "import os\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "def load_document(folder_path: str) -> List[Document]:\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif filename.endswith('.docx'):\n",
    "            loader = Docx2txtLoader(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {filename}\")\n",
    "            continue\n",
    "        documents.extend(loader.load())\n",
    "    return documents\n",
    "folder_path = \"C:/Users/ladha/Machine Learning/RAG Chatbot/docs\"\n",
    "\n",
    "documents = load_document(folder_path)\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents from the folder.\")\n",
    "split = text_splitter.split_documents(documents)\n",
    "print(f\"Split the documents into {len(split)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e95c95a-02f2-4ddf-8312-551c4899176a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-09-21T21:41:12+05:30', 'author': 'JASH LADHANI - 70322100155', 'moddate': '2025-09-21T21:41:12+05:30', 'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\amazon_report.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}, page_content=\"Letter from the CEO \\nDear Shareholders, \\n2023 was a year of transformation and growth for Amazon. We continued to innovate on behalf of \\nour customers while making significant investments in emerging technologies, sustainability, and \\nglobal expansion. Our relentless focus on customer obsession, long-term thinking, and operational \\nexcellence has enabled us to deliver strong results across all our business segments. \\nWe expanded our leadership in cloud computing, revolutionized logistics and delivery, and pioneered \\nnew frontiers in artificial intelligence and machine learning. Our commitment to being Earth's Most \\nCustomer-Centric Company remains unwavering as we build for the next decade of growth. \\nCompany Overview \\nAmazon.com, Inc. is a multinational technology company focusing on e-commerce, cloud computing, \\ndigital streaming, and artificial intelligence. Founded in 1994, Amazon has grown to become one of\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d745225-a1df-4742-8101-893aefd74573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-09-21T21:41:12+05:30', 'author': 'JASH LADHANI - 70322100155', 'moddate': '2025-09-21T21:41:12+05:30', 'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\amazon_report.pdf', 'total_pages': 3, 'page': 0, 'page_label': '1'}\n",
      "Letter from the CEO \n",
      "Dear Shareholders, \n",
      "2023 was a year of transformation and growth for Amazon. We continued to innovate on behalf of \n",
      "our customers while making significant investments in emerging technologies, sustainability, and \n",
      "global expansion. Our relentless focus on customer obsession, long-term thinking, and operational \n",
      "excellence has enabled us to deliver strong results across all our business segments. \n",
      "We expanded our leadership in cloud computing, revolutionized logistics and delivery, and pioneered \n",
      "new frontiers in artificial intelligence and machine learning. Our commitment to being Earth's Most \n",
      "Customer-Centric Company remains unwavering as we build for the next decade of growth. \n",
      "Company Overview \n",
      "Amazon.com, Inc. is a multinational technology company focusing on e-commerce, cloud computing, \n",
      "digital streaming, and artificial intelligence. Founded in 1994, Amazon has grown to become one of\n"
     ]
    }
   ],
   "source": [
    "print(split[0].metadata)\n",
    "print(split[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee80b040-716f-4947-a080-fa677e0132f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we create embeddings for the RAG Systems\n",
    "\n",
    "#We canuse either google gemini embeddings or Transformers\n",
    "#from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "#1. Gemini embeddings\n",
    "#embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "#document_embeddings = embeddings.embed_documents([split.page_content for split in split])\n",
    "#print(f\"Created embeddings for {len(document_embeddings)} document chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eff2e31d-e230-4358-a0dd-4c387c2525cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using sentence transformers\n",
    "#!pip install -U langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a5c5d28-9950-44dc-98d0-efb5d9c9c94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02229335904121399,\n",
       " -0.09387563169002533,\n",
       " 0.06080594286322594,\n",
       " -0.040375541895627975,\n",
       " 0.04493541270494461,\n",
       " -0.023383354768157005,\n",
       " -0.02749449387192726,\n",
       " -0.0476890429854393,\n",
       " 0.07645419985055923,\n",
       " -0.0016002620104700327,\n",
       " -0.010110734961926937,\n",
       " 0.0703221932053566,\n",
       " 0.04522973671555519,\n",
       " -0.049691181629896164,\n",
       " 0.005457814317196608,\n",
       " -0.04428117349743843,\n",
       " -0.04753728583455086,\n",
       " -0.14613069593906403,\n",
       " -0.10447579622268677,\n",
       " -0.07812505960464478,\n",
       " -0.057936765253543854,\n",
       " 0.037363916635513306,\n",
       " -0.001877667848020792,\n",
       " 0.04227926582098007,\n",
       " -0.08310526609420776,\n",
       " 0.10157390683889389,\n",
       " -0.022628696635365486,\n",
       " 0.03692926838994026,\n",
       " -0.026070842519402504,\n",
       " -0.0392434298992157,\n",
       " 0.025050614029169083,\n",
       " 0.0031171604059636593,\n",
       " 0.11538727581501007,\n",
       " 0.05133163556456566,\n",
       " -0.06464819610118866,\n",
       " 0.01940147392451763,\n",
       " -0.0559970960021019,\n",
       " -0.07019898295402527,\n",
       " 0.030206289142370224,\n",
       " -0.00016518098709639162,\n",
       " 0.0438443198800087,\n",
       " -0.03930535167455673,\n",
       " -0.03678524121642113,\n",
       " -0.002570848912000656,\n",
       " 0.07627523690462112,\n",
       " 0.010885367169976234,\n",
       " -0.016742991283535957,\n",
       " 0.007712367922067642,\n",
       " 0.03277363255620003,\n",
       " 0.032779060304164886,\n",
       " -0.03112752176821232,\n",
       " -0.05509217455983162,\n",
       " 0.061288848519325256,\n",
       " -0.03166389465332031,\n",
       " -0.0649162009358406,\n",
       " 0.03849257156252861,\n",
       " -0.029588721692562103,\n",
       " -0.021743346005678177,\n",
       " 0.01289680041372776,\n",
       " -0.04981977492570877,\n",
       " 0.05677667260169983,\n",
       " -0.10376472771167755,\n",
       " 0.14080233871936798,\n",
       " 0.03130008652806282,\n",
       " 0.03968172147870064,\n",
       " 0.046237196773290634,\n",
       " -0.001493088435381651,\n",
       " -0.002522389404475689,\n",
       " -0.04491892457008362,\n",
       " -0.014573663473129272,\n",
       " -0.002861704910174012,\n",
       " -0.04180062189698219,\n",
       " -0.014000625349581242,\n",
       " 0.0978565365076065,\n",
       " -0.043378956615924835,\n",
       " 0.03523000329732895,\n",
       " 0.05539555102586746,\n",
       " 0.025295669212937355,\n",
       " 0.031548671424388885,\n",
       " 0.0766180157661438,\n",
       " -0.027353031560778618,\n",
       " 0.03989532217383385,\n",
       " -0.04349539056420326,\n",
       " 0.06887543201446533,\n",
       " -0.1340540051460266,\n",
       " 0.010252370499074459,\n",
       " 0.07367536425590515,\n",
       " -0.0062815784476697445,\n",
       " -0.0800219401717186,\n",
       " -0.029810622334480286,\n",
       " -0.0008056285441853106,\n",
       " -0.08047543466091156,\n",
       " 0.07017961889505386,\n",
       " 0.010837667621672153,\n",
       " -0.09210235625505447,\n",
       " -0.00432939687743783,\n",
       " -0.07399643212556839,\n",
       " -0.10816626250743866,\n",
       " -0.03853641450405121,\n",
       " -0.0737352967262268,\n",
       " 0.014018421061336994,\n",
       " 0.06448189169168472,\n",
       " 0.0264583807438612,\n",
       " -0.08425043523311615,\n",
       " -0.02128101885318756,\n",
       " -0.043396785855293274,\n",
       " -0.021904274821281433,\n",
       " 0.08465782552957535,\n",
       " 0.03734331950545311,\n",
       " -0.0086421649903059,\n",
       " -0.0418856181204319,\n",
       " -0.026543226093053818,\n",
       " -0.03775043785572052,\n",
       " -0.031217502430081367,\n",
       " -0.0009750468307174742,\n",
       " -0.005524045322090387,\n",
       " -0.12263192981481552,\n",
       " 0.0658312737941742,\n",
       " 0.13582949340343475,\n",
       " -0.009322860278189182,\n",
       " 0.07329542934894562,\n",
       " 0.03174743428826332,\n",
       " 0.022849444299936295,\n",
       " -0.03577607125043869,\n",
       " -0.03310893103480339,\n",
       " -0.05395369604229927,\n",
       " -0.07106281071901321,\n",
       " -1.5623246312995695e-34,\n",
       " -0.05574870482087135,\n",
       " 0.07151047140359879,\n",
       " 0.0045474823564291,\n",
       " 0.00615046638995409,\n",
       " -0.011143115349113941,\n",
       " 0.01548603642731905,\n",
       " 0.004457020200788975,\n",
       " 0.1221206933259964,\n",
       " -0.09104156494140625,\n",
       " -0.01772167719900608,\n",
       " -0.046476099640131,\n",
       " 0.05171123147010803,\n",
       " 0.04537956044077873,\n",
       " 0.006970912218093872,\n",
       " -0.017241384834051132,\n",
       " -0.04675831273198128,\n",
       " -0.029007844626903534,\n",
       " -0.006921087391674519,\n",
       " 0.030374856665730476,\n",
       " -0.030264075845479965,\n",
       " 0.06994584947824478,\n",
       " 0.007661563344299793,\n",
       " -0.0036399911623448133,\n",
       " 0.04109203442931175,\n",
       " 0.02373371087014675,\n",
       " -0.05905256047844887,\n",
       " -0.014993944205343723,\n",
       " 0.007953084073960781,\n",
       " 0.08985605090856552,\n",
       " 0.012036554515361786,\n",
       " 0.0658041462302208,\n",
       " -0.004694077651947737,\n",
       " -0.06953441351652145,\n",
       " -0.04067079722881317,\n",
       " -0.051891256123781204,\n",
       " -0.0286865197122097,\n",
       " -0.06591115146875381,\n",
       " 0.030645882710814476,\n",
       " 0.028235314413905144,\n",
       " 0.04968958720564842,\n",
       " -0.023402832448482513,\n",
       " 0.0413350835442543,\n",
       " -0.08330406993627548,\n",
       " 0.003104502335190773,\n",
       " -0.028342226520180702,\n",
       " 0.036405790597200394,\n",
       " 0.030564704909920692,\n",
       " 0.016623863950371742,\n",
       " 0.1076083853840828,\n",
       " 0.032942987978458405,\n",
       " -0.0847703069448471,\n",
       " -0.06137226149439812,\n",
       " 0.10794886946678162,\n",
       " -0.011433528736233711,\n",
       " 0.0756787657737732,\n",
       " -0.016310768201947212,\n",
       " 0.010535858571529388,\n",
       " 0.0030837443191558123,\n",
       " 0.0035815963055938482,\n",
       " -0.00197711493819952,\n",
       " -0.0440443679690361,\n",
       " -0.0005881378310732543,\n",
       " -0.034029796719551086,\n",
       " 0.09488657861948013,\n",
       " -0.08608195930719376,\n",
       " 0.0032563512213528156,\n",
       " 0.10785471647977829,\n",
       " 0.043623730540275574,\n",
       " 0.005739283282309771,\n",
       " 0.03509923070669174,\n",
       " 0.0703839361667633,\n",
       " 0.03343365713953972,\n",
       " 0.0346558541059494,\n",
       " 0.020421745255589485,\n",
       " -0.030903751030564308,\n",
       " -0.02726181223988533,\n",
       " -0.03928890451788902,\n",
       " -0.030951090157032013,\n",
       " 0.006300508044660091,\n",
       " 0.05782265588641167,\n",
       " -0.002566474722698331,\n",
       " 0.07167192548513412,\n",
       " 0.06028515473008156,\n",
       " 0.018231119960546494,\n",
       " -0.009966844692826271,\n",
       " 0.01237864512950182,\n",
       " 0.04930055886507034,\n",
       " 0.04167085513472557,\n",
       " -0.03449513018131256,\n",
       " 0.04854150116443634,\n",
       " -0.035580459982156754,\n",
       " 0.015929395332932472,\n",
       " 0.03655494749546051,\n",
       " 0.06548391282558441,\n",
       " -0.00788510125130415,\n",
       " -1.2959979501449265e-33,\n",
       " 0.04327787086367607,\n",
       " 0.0026854113675653934,\n",
       " -0.011064207181334496,\n",
       " 0.053697969764471054,\n",
       " -0.009233621880412102,\n",
       " -0.05228613689541817,\n",
       " 0.02615540474653244,\n",
       " 0.06976066529750824,\n",
       " -0.03351413458585739,\n",
       " -0.0009732532780617476,\n",
       " 0.009095205925405025,\n",
       " 0.06797166168689728,\n",
       " -0.02756652794778347,\n",
       " -0.019582444801926613,\n",
       " -0.04211541637778282,\n",
       " -0.02707492932677269,\n",
       " 0.02686593122780323,\n",
       " -0.12612032890319824,\n",
       " -0.04984116926789284,\n",
       " -0.06815896928310394,\n",
       " -0.021543897688388824,\n",
       " -0.06991162896156311,\n",
       " -0.06809332221746445,\n",
       " -0.06711530685424805,\n",
       " 0.022374454885721207,\n",
       " 0.05113842710852623,\n",
       " 0.0037495458964258432,\n",
       " 0.013795940205454826,\n",
       " 0.027516305446624756,\n",
       " -0.03350885957479477,\n",
       " -0.060394447296857834,\n",
       " 0.021086091175675392,\n",
       " -0.03659792244434357,\n",
       " 0.045853275805711746,\n",
       " -0.0068784067407250404,\n",
       " -0.015847712755203247,\n",
       " -0.051981378346681595,\n",
       " 0.0018909485079348087,\n",
       " 0.027322929352521896,\n",
       " -0.028128216043114662,\n",
       " 0.04127385839819908,\n",
       " 0.01935611106455326,\n",
       " 0.034365538507699966,\n",
       " -0.037124816328287125,\n",
       " -0.008221978321671486,\n",
       " 0.011449754238128662,\n",
       " -0.0016952244332060218,\n",
       " 0.004195092711597681,\n",
       " 0.05688295140862465,\n",
       " 0.036120954900979996,\n",
       " -0.08907942473888397,\n",
       " 0.0013671310152858496,\n",
       " 0.04908357933163643,\n",
       " -0.0410008579492569,\n",
       " -0.007195203565061092,\n",
       " 0.05941273272037506,\n",
       " -0.004752489272505045,\n",
       " 0.08243343234062195,\n",
       " 0.010100767947733402,\n",
       " -0.013395769521594048,\n",
       " -0.02742673084139824,\n",
       " -0.038062889128923416,\n",
       " 0.0914505273103714,\n",
       " 0.05567624047398567,\n",
       " -0.10470021516084671,\n",
       " 0.004367190878838301,\n",
       " 0.049544546753168106,\n",
       " 0.03829871118068695,\n",
       " -0.04852423816919327,\n",
       " -0.05784277617931366,\n",
       " 0.01140926405787468,\n",
       " -0.06257269531488419,\n",
       " -0.061483338475227356,\n",
       " -0.07969050109386444,\n",
       " -0.11105521768331528,\n",
       " 0.03245778754353523,\n",
       " -0.02473689801990986,\n",
       " -0.11359740793704987,\n",
       " -0.054526712745428085,\n",
       " -0.019665954634547234,\n",
       " 0.04277747496962547,\n",
       " 0.04185308516025543,\n",
       " 0.0026817000471055508,\n",
       " 0.050830237567424774,\n",
       " 0.05238480865955353,\n",
       " 0.05285842344164848,\n",
       " -0.006458279211074114,\n",
       " -0.03981167450547218,\n",
       " -0.0637441948056221,\n",
       " 0.053541649132966995,\n",
       " -0.04831647872924805,\n",
       " -0.07038316875696182,\n",
       " -0.0982418805360794,\n",
       " -0.012427221052348614,\n",
       " -0.0514821894466877,\n",
       " -5.389167867519973e-08,\n",
       " -0.01986679434776306,\n",
       " -0.048392362892627716,\n",
       " 0.09421990811824799,\n",
       " 0.03755657374858856,\n",
       " 0.1229119673371315,\n",
       " 0.030294453725218773,\n",
       " 0.11673693358898163,\n",
       " 0.04606926068663597,\n",
       " 0.0305972658097744,\n",
       " 0.01658538170158863,\n",
       " 0.022038178518414497,\n",
       " -0.08698029071092606,\n",
       " -0.09622180461883545,\n",
       " 0.06265071779489517,\n",
       " 0.0678078904747963,\n",
       " 0.013497213833034039,\n",
       " -0.014563274569809437,\n",
       " 0.052248433232307434,\n",
       " 0.040758535265922546,\n",
       " -0.012395539321005344,\n",
       " -0.03531701862812042,\n",
       " -0.006737114861607552,\n",
       " 0.013402247801423073,\n",
       " -0.043559230864048004,\n",
       " 0.021189136430621147,\n",
       " 0.032556962221860886,\n",
       " 0.0020172325894236565,\n",
       " -0.01682959496974945,\n",
       " 0.00017663762264419347,\n",
       " -0.050618816167116165,\n",
       " -0.024207374081015587,\n",
       " -0.049561358988285065,\n",
       " 0.027228061109781265,\n",
       " -0.016224969178438187,\n",
       " -0.014671051874756813,\n",
       " -0.06134316697716713,\n",
       " -0.02307559736073017,\n",
       " 0.004903409164398909,\n",
       " -0.04342721030116081,\n",
       " -0.013468311168253422,\n",
       " 0.01253938302397728,\n",
       " 0.1017179861664772,\n",
       " -0.0024307691492140293,\n",
       " 0.01020396314561367,\n",
       " 0.049708668142557144,\n",
       " -0.0670265406370163,\n",
       " -0.07507370412349701,\n",
       " 0.053966671228408813,\n",
       " -0.012434408068656921,\n",
       " -3.482845568214543e-05,\n",
       " 0.006926520727574825,\n",
       " -0.002419933909550309,\n",
       " 0.04300713911652565,\n",
       " 0.09538491070270538,\n",
       " 0.023484934121370316,\n",
       " 0.005713281687349081,\n",
       " 0.012626389972865582,\n",
       " -0.060158152133226395,\n",
       " -0.005958499386906624,\n",
       " 0.12373757362365723,\n",
       " 0.01099629607051611,\n",
       " -0.04326031729578972,\n",
       " 0.009061459451913834,\n",
       " 0.028052380308508873]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_function = HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\")\n",
    "document_embeddings = embedding_function.embed_documents([split.page_content for split in split])\n",
    "document_embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d53c7e5-0bfe-4c8f-952e-1527bda236a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created and persisted to './chroma_db'\n"
     ]
    }
   ],
   "source": [
    "#Now we store these embeddings\n",
    "\n",
    "#We use ChromaDB as VectorDB\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "embedding_function = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "collection_name = \"my_collection\"\n",
    "vectorstore = Chroma.from_documents(collection_name = collection_name, documents=split, embedding=embedding_function, persist_directory=\"./chroma_db\")\n",
    "\n",
    "print(\"Vector store created and persisted to './chroma_db'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf57b6b2-7d8a-4e97-b19e-83b3119700a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 relevent chunks for the query: 'When was amazon founded?'\n",
      "\n",
      "Result 1: \n",
      "Source: C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\amazon_report.pdf\n",
      "Content: Letter from the CEO \n",
      "Dear Shareholders, \n",
      "2023 was a year of transformation and growth for Amazon. We continued to innovate on behalf of \n",
      "our customers while making significant investments in emerging technologies, sustainability, and \n",
      "global expansion. Our relentless focus on customer obsession, long-term thinking, and operational \n",
      "excellence has enabled us to deliver strong results across all our business segments. \n",
      "We expanded our leadership in cloud computing, revolutionized logistics and delivery, and pioneered \n",
      "new frontiers in artificial intelligence and machine learning. Our commitment to being Earth's Most \n",
      "Customer-Centric Company remains unwavering as we build for the next decade of growth. \n",
      "Company Overview \n",
      "Amazon.com, Inc. is a multinational technology company focusing on e-commerce, cloud computing, \n",
      "digital streaming, and artificial intelligence. Founded in 1994, Amazon has grown to become one of\n",
      "\n",
      "Result 2: \n",
      "Source: C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\amazon_report.pdf\n",
      "Content: Letter from the CEO \n",
      "Dear Shareholders, \n",
      "2023 was a year of transformation and growth for Amazon. We continued to innovate on behalf of \n",
      "our customers while making significant investments in emerging technologies, sustainability, and \n",
      "global expansion. Our relentless focus on customer obsession, long-term thinking, and operational \n",
      "excellence has enabled us to deliver strong results across all our business segments. \n",
      "We expanded our leadership in cloud computing, revolutionized logistics and delivery, and pioneered \n",
      "new frontiers in artificial intelligence and machine learning. Our commitment to being Earth's Most \n",
      "Customer-Centric Company remains unwavering as we build for the next decade of growth. \n",
      "Company Overview \n",
      "Amazon.com, Inc. is a multinational technology company focusing on e-commerce, cloud computing, \n",
      "digital streaming, and artificial intelligence. Founded in 1994, Amazon has grown to become one of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Similarity search\n",
    "\n",
    "#Through this we get matching documents\n",
    "query = \"When was amazon founded?\"\n",
    "search_results = vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"Top 2 relevent chunks for the query: '{query}'\\n\")\n",
    "for i, result in enumerate(search_results,1):\n",
    "    print(f\"Result {i}: \")\n",
    "    print(f\"Source: {result.metadata.get('source','unknown')}\")\n",
    "    print(f\"Content: {result.page_content}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "545828cf-5aa0-4682-beb9-756a29ad23c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='c736e426-2b9e-4321-9e80-96a293165573', metadata={'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\JPMorgan_Annual_Report.docx'}, page_content=\"JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a\"),\n",
       " Document(id='260234e4-3512-4c31-8010-c5ce90bc9261', metadata={'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\JPMorgan_Annual_Report.docx'}, page_content=\"JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a\")]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We cant store this vectorstore output inside the chain, so we need to convert it to the retriever object\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":2})\n",
    "retriever.invoke(\"When was jpmorgan founded?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "858374e3-b057-4dc7-aed5-85f27a9a2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add the retriever to the chain\n",
    "#We will first create a template and prompt for our model to work perfectly\n",
    "from langchain_core.prompts import ChatMessagePromptTemplate\n",
    "template = \"\"\"Answer the question based on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8a10257-c634-4628-ba5f-9d328f18574e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Answer the question based on the following context:\\n[Document(id=\\'7af4b431-a6dc-484d-b85c-1666b9381489\\', metadata={\\'source\\': \\'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\\\\\JPMorgan_Annual_Report.docx\\'}, page_content=\"assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world\\'s most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world\\'s most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world\\'s most prominent corporate, institutional, and government clients.\"), Document(id=\\'a3bcf86a-b06c-4b70-a138-ed13a5a6d0ce\\', metadata={\\'source\\': \\'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\\\\\JPMorgan_Annual_Report.docx\\'}, page_content=\"assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world\\'s most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world\\'s most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world\\'s most prominent corporate, institutional, and government clients.\")]\\n\\nQuestion: Asset values of JP Morgan\\n\\nAnswer:\\n', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can build our chain and also use langchain's pre built chain\n",
    "#We will first build our own chain\n",
    "\n",
    "#In our chain, we create a dictionary and pass to the prompt so that the model can dynamically take input questions and context\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt    #RunnablePassThrough is basically what we pss in invoke\n",
    ")\n",
    "rag_chain.invoke(\"Asset values of JP Morgan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57d3badb-fda1-4e56-849a-eb8664f1d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently the model provides extra info while we only need the content\n",
    "\n",
    "def doc2str(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)  #fetches texts for the selected documents and joins them and seperates using \\n\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b093bb67-fd76-417d-93c8-28f5e6078440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"Answer the question based on the following context:\\nassets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients.\\n\\nassets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients.\\n\\nQuestion: Asset values of JP Morgan\\n\\nAnswer:\\n\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we update the chain to pass the retriever through this new function that we created\\\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | doc2str, \"question\": RunnablePassthrough()} | prompt    #RunnablePassThrough is basically what we pss in invoke\n",
    ")\n",
    "rag_chain.invoke(\"Asset values of JP Morgan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af5e09bb-6a38-4450-8127-d914b4bdf695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPMorgan Chase & Co. has assets exceeding $3.9 trillion.\n"
     ]
    }
   ],
   "source": [
    "#Now we add llm to the chain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | doc2str, \"question\": RunnablePassthrough()} #RunnablePassThrough is basically what we pss in invoke\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "question = \"Asset values of JP Morgan\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e999820-f35e-479f-9baa-8df965dacceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So now the model answers the question but it won't be able to answer followup questions since it is not a conversational model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ed8dd87-9e97-4cd0-9f79-71a3120d4d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For conversational RAG\n",
    "\n",
    "#First we introduce the chat history\n",
    "chat_history = []\n",
    "chat_history.extend([\n",
    "    HumanMessage(content=question),\n",
    "    SystemMessage(content=response)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad75cc75-69e5-4ced-936e-2df4b53a4407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Asset values of JP Morgan', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='JPMorgan Chase & Co. has assets exceeding $3.9 trillion.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80f7429b-36b7-4baf-91cf-1f441c078ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Where is JPMorgan Chase & Co.'s headquarters?\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To handle followup questions we contextualize our system\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "contextualize_q_system_prompt = (\n",
    "    \"\"\"\n",
    "Given a chat history and the latest user question\n",
    "which might reference context in the chat history,\n",
    "formulate a standalone question which can be understood\n",
    "without the chat history. Do NOT answer the question,\n",
    "just reformulate it if needed and otherwise return it as is.\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "contextualize_chain = contextualize_q_prompt | llm | StrOutputParser()\n",
    "contextualize_chain.invoke({\"input\": \"Where is it's headquaters?\", \"chat_history\":chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f716733c-4a0b-4e35-819e-d95b976ca927",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above o/p is right, it doesnt provide answer yet, it was only required to contextualize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8d5c580-8daa-4a9d-802f-0da3f34ee112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='a3bcf86a-b06c-4b70-a138-ed13a5a6d0ce', metadata={'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\JPMorgan_Annual_Report.docx'}, page_content=\"assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients.\"),\n",
       " Document(id='11a9eca2-dcfb-40a6-84c0-1e54353c77d5', metadata={'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\JPMorgan_Annual_Report.docx'}, page_content=\"assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients.\")]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will now make our model history aware\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt                           #to create history aware retriever, it uses our llm and normal retriever that we made above and the contextualize_q_prompt which we used to make our model understand context\n",
    ")\n",
    "history_aware_retriever.invoke({\"input\":\"Where is it's headquarter?\", \"chat_history\":chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbdc3161-3386-40f5-90c9-7acf1e25774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How many customers in the United States do they serve?',\n",
       " 'chat_history': [HumanMessage(content='Asset values of JP Morgan', additional_kwargs={}, response_metadata={}),\n",
       "  SystemMessage(content='JPMorgan Chase & Co. has assets exceeding $3.9 trillion.', additional_kwargs={}, response_metadata={})],\n",
       " 'context': [Document(id='ca522cea-31fe-42fe-bc03-70e736d30195', metadata={'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\JPMorgan_Annual_Report.docx'}, page_content=\"assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients.\"),\n",
       "  Document(id='11a9eca2-dcfb-40a6-84c0-1e54353c77d5', metadata={'source': 'C:/Users/ladha/Machine Learning/RAG Chatbot/docs\\\\JPMorgan_Annual_Report.docx'}, page_content=\"assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients. JPMorgan Chase & Co. is a leading global financial services firm with assets exceeding $3.9 trillion. We serve millions of customers in the United States and many of the world's most prominent corporate, institutional, and government clients.\")],\n",
       " 'answer': 'JPMorgan Chase & Co. has assets exceeding **$3.9 trillion**.\\n\\nThey serve **millions** of customers in the United States.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we create a final chain to join everything to create final llm\n",
    "#Creating another prompt to adapt to above updates\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are a helpful AI assistant. Use the following context to answer the user's question\"),\n",
    "    (\"system\",\"Context: {context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\",\"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
    "rag_chain.invoke({\"input\":\"How many customers in the United States do they serve?\", \"chat_history\":chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68c3f214-b7c3-45c9-8ba4-30d7d9e96e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using SQLite database to store everything\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "DB_NAME = \"rag_app.db\"\n",
    "\n",
    "def get_db_connection():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    conn.row_factory = sqlite3.Row     #Normally sql queries return tuples, to make it more readable we do this. This converts the queries to a dictionary \n",
    "    return conn\n",
    "def create_application_logs():\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('''CREATE TABLE IF NOT EXISTS application_logs\n",
    "    (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    session_id TEXT,\n",
    "    user_query TEXT,\n",
    "    gpt_response TEXT,\n",
    "    model TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )'''\n",
    "    )\n",
    "    conn.close()\n",
    "\n",
    "#function to capture session id, what user asked, what response and he got and then it will save it inside the above table \n",
    "def insert_application_logs(session_id, user_query, gpt_response, model):\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('INSERT INTO application_logs (session_id, user_query, gpt_response, model) VALUES (?, ?, ?, ?)',\n",
    "                (session_id, user_query, gpt_response, model))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "#To get chat history for a particular session\n",
    "def get_chat_history(session_id):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT user_query, gpt_response FROM application_logs WHERE session_id = ? ORDER BY created_at',(session_id,))\n",
    "    messages = []\n",
    "    for row in cursor.fetchall():\n",
    "        messages.extend([\n",
    "            {\"role\":\"human\", \"content\":row['user_query']},\n",
    "            {\"role\":\"ai\", \"content\":row['gpt_response']}\n",
    "        ])\n",
    "    conn.close()\n",
    "    return messages\n",
    "\n",
    "# Initialize the database\n",
    "create_application_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4dc43772-4ff3-48bf-9bd6-8a4798f83675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Human: when was amazon founded?\n",
      "AI: Amazon was founded in **1994**.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "session_id = str(uuid.uuid4())\n",
    "chat_history = get_chat_history(session_id)\n",
    "print(chat_history)\n",
    "q1 = \"when was amazon founded?\"\n",
    "a1 = rag_chain.invoke({\"input\":q1,\"chat_history\":chat_history})['answer']\n",
    "insert_application_logs(session_id, q1, a1, \"gemini-2.5-flash\")\n",
    "print(f\"Human: {q1}\")\n",
    "print(f\"AI: {a1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aa2e84ca-117f-4a68-b75f-44591acf15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Give a short summary on it's features?\n",
      "AI: Amazon.com, Inc. is a multinational technology company primarily focused on **e-commerce, cloud computing (AWS), digital streaming, and artificial intelligence**. Founded in 1994, it operates globally in over 180 countries, serving hundreds of millions of customers and employing over 1.5 million people. Its mission is to be Earth's Most Customer-Centric Company, Best Employer, and Safest Place to Work. Its business is divided into **North America and International segments**, both handling retail sales of consumer products and subscriptions through online stores, including export sales.\n"
     ]
    }
   ],
   "source": [
    "q2 = \"Give a short summary on it's features?\"\n",
    "chat_history = get_chat_history(session_id)\n",
    "a2 = rag_chain.invoke({\"input\": q2, \"chat_history\": chat_history})['answer']\n",
    "insert_application_logs(session_id, q2, a2, \"gemini-2.5-pro\")\n",
    "print(f\"Human: {q2}\")\n",
    "print(f\"AI: {a2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1fbf8814-76a1-474b-ab78-7f98f8a8113c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Human: Asset value of JP Morgan bank?\n",
      "AI: JPMorgan Chase & Co. has assets exceeding $3.9 trillion.\n"
     ]
    }
   ],
   "source": [
    "#For new user\n",
    "session_id = str(uuid.uuid4())\n",
    "chat_history = get_chat_history(session_id)\n",
    "print(chat_history)\n",
    "q1 = \"Asset value of JP Morgan bank?\"\n",
    "a1 = rag_chain.invoke({\"input\":q1,\"chat_history\":chat_history})['answer']\n",
    "insert_application_logs(session_id, q1, a1, \"gemini-2.5-flash\")\n",
    "print(f\"Human: {q1}\")\n",
    "print(f\"AI: {a1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b31db849-fb34-4e94-bf8a-215ea631e3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: How many customers do they have in the US?\n",
      "AI: JPMorgan Chase & Co. serves millions of customers in the United States.\n"
     ]
    }
   ],
   "source": [
    "q2 = \"How many customers do they have in the US?\"\n",
    "chat_history = get_chat_history(session_id)\n",
    "a2 = rag_chain.invoke({\"input\": q2, \"chat_history\": chat_history})['answer']\n",
    "insert_application_logs(session_id, q2, a2, \"gemini-2.5-pro\")\n",
    "print(f\"Human: {q2}\")\n",
    "print(f\"AI: {a2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fee63dd6-a523-4dad-aed5-d674fa40658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are done with RAG LLM\n",
    "#Now we will make it production ready and deploy using FastAPI\n",
    "\n",
    "#We will basically be creating an API\n",
    "#We will convert our collab notebook into an API\n",
    "#Learn how any frontend ->streamlit react.js etc communicate with our API\n",
    "#Also learn to manage session ids so that model is capable of answering followup questions for that particular session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b54a1e-49ed-41f1-a968-6f3bcfe3eac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
